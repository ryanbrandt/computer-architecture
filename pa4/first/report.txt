The only real data structure I leveraged for this assignment was essentially a Matrix. I made a "Line" struct to represent individual cache lines, which had members to hold a tag value and keep track of usage/rank relative to an individual Lines' set for the LRU algorithm. My cache was essentially a Matrix or 2-d array, which held Line instances. In reflection I would have preferred a Hash Table, but I found myself struggling with the logic behind this assignment for significantly longer than I had anticipated, so I went for a simpler, though likely less efficient implementation with a Matrix. 

Through testing with my own files, I definitely noticed substantial improvements as far as hits go with the prefetcher. In most cases I tried, it seemed to generally double the hits. This can be attributed to the fact that, when running programs, if one memory address is accessed, it is likely in the near future that a neighbor of this address will also be accessed. For instance, with arrays, which represent contiguous memory, a pretty ubiquitous operation is traversing an array. So, if we miss and write the address corresponding to arr[0], and prefetch its neighbor arr[1], we can clearly see how our hit-to-miss ratio can improve.
